+++
title = "阅读笔记 - On the Effectiveness of Low Frequency Perturbations"
summary = "本文通过系统地控制扰动的频率分量，评估了NeurIPS 2017竞赛中排在首位的防御方法的性能，来测试不同频率分量的扰动的有效性。结果表明：**当扰动限制在低频子空间时，它们生成更快，迁移性更好**。如果扰动限制在其他频率子空间，性能普遍会变差。**这证实了低频扰动的有效性是因为在频率域应用了低通滤波器而不是由于搜索维度的减少。**"
authors = ["duyang"]
tags = ["科研","深度学习"]
toc = true
categories = ["科研"]
series = ["频率"]
date = "2020-12-09"
lastmod = "2020-12-09"
draft = false

+++


## 论文信息

| Title                                               | Authors                                                  | Publication |
| --------------------------------------------------- | -------------------------------------------------------- | ----------- |
| On the Effectiveness of Low Frequency Perturbations | Yash Sharma, Gavin Weiguang Ding, and Marcus A. Brubaker | IJCAI 2019  |

## 前言

这篇文章第一作者是Yash Sharma，是经典对抗攻击方法ZOO的合作作者之一。

## 摘要

经过精心设计的不可察觉的对抗扰动会导致当前最先进的模型产生不准确的输出，使得他们无法适用于对安全程度要求严格的应用领域。

本文的目标是调查扰动的频率属性与它的有效性之间的关系。最近的一些工作表示将攻击空间约束到低频区域十分有效。但目前主要存在两个未解决的问题：

1. 低频扰动的有效性是因为**搜索空间减少**还是因为**特地使用了低频分量**？
2. 在什么条件下低频扰动比非限制扰动更有效？

为了回答这些问题，本文通过系统地控制扰动的频率分量，评估了NeurIPS 2017竞赛中排在首位的防御方法的性能，来测试不同频率分量的扰动的有效性。

结果表明：**当扰动限制在低频子空间时，它们生成更快，迁移性更好**。如果扰动限制在其他频率子空间，性能普遍会变差。**这证实了低频扰动的有效性是因为在频率域应用了低通滤波器而不是由于搜索维度的减少。**

实际上，基于对抗训练的防御模型与未防御模型大致一样难以抵抗低频扰动，这表明，最新的ImageNet防御的所谓健壮性取决于对抗扰动本质上是高频的。 我们确实发现，在$l_{\infty}=16/255$的情况下，低频扰动确实是可感知的。 这就说明将$l_{\infty}$范数用作失真度量可能并不合理，并且反过来表明，明确考虑频率空间对于学习更好地与人的感知相适应的鲁棒模型是有前途的。

## 方法

### 攻击

本文扰动约束采用$l_{\infty}$范数。最大扰动幅度$\epsilon=16$，与NeurIPS 2017竞赛一致。本文采用改进版的FGSM（Fast Gradient Sign Method）作为攻击方法即清华大学朱军团队的董胤蓬博士提出的基于动量的迭代方法，Momentum Iterative Method (MIM)[1]。原始的FGSM可用下式表示
$$\delta_{\mathrm{FGSM}}=s\cdot \epsilon \cdot \operatorname{sign}\left(\nabla_{x} J(x, y)\right)$$

其中$x$是输入图像，$J$是损失函数，$\operatorname{sign}(\cdot)$是符号函数。当$y$是$x$的真实标签并且$s=+1$，$\delta$是无目标攻击；当$y$是目标标签并且$s=-1$，$\delta$是有目标攻击。

### 频率限制

本文采用离散余弦变换（DCT）来限制频率的扰动范围。将$x$的DCT变换表示为$v=\operatorname{DCT}(x)$。DCT变换是可逆的，逆DCT变换表示为$x=\operatorname{IDCT}(v)$。

本文为了比较不同频率分量的性能，对图像的频域采用了一个遮罩$m$（mask）。遮罩$m\in \{0,1\}^{d\times d}$，是一个二维像素矩阵，像素值为0或1（对应到8位灰度图就是0和255）。遮罩操作通过按元素乘积。然后通过应用逆DCT变换到遮罩后的DCT系数来重建变换后的扰动。完整的变换过程可以用下式表示：

$$\text { FreqMask }(\delta)=\operatorname{IDCT}(\operatorname{Mask}(\operatorname{DCT}(\delta))).$$

所以本文的攻击中，梯度信息表示如下：

$$\nabla_{\delta} J(x+\text { FreqMask }(\delta), y).$$

本文设计了四种类型的频率遮罩来限制扰动区域，如下图所示：

![image-20201210112216965](https://i.loli.net/2020/12/10/mcirJnDVAKoaOk3.png)

其中DCT_High只保留高频分量，DCT_Low只保留低频分量，DCT_Mid只保留低频分量， DCT_Random随机保留分量。对于原始尺寸为$d\times d$的图像，缩小维度到$n$，即只保留$n\times n$的频率分量。

## 实验结果

本文采用对抗样本的攻击成功率(attack success rate，ASR)作为评价指标。同时考虑了有目标攻击和无目标攻击的场景。对于无目标攻击，测试了$\epsilon=16$且迭代次数在1和10时的实验结果；对于有目标攻击，测试了$\epsilon=32$且迭代次数在10时的实验结果。

遮罩$m$尺寸有四种设置，即$n=[256,128,64,32]$。下图是部分实验结果：

![image-20201210115526635](https://i.loli.net/2020/12/10/GY5ApdZVfXnsi6w.png)

可以看到低频分量模式（DCT_low）下的ASR一直是超过其他频率分量的。同时，在论文附录部分，作者还展示了通过使用一个空间平滑滤波器或下采样上采样滤波器（使用双线性插值法重设扰动尺寸）来对扰动进行一定限制。从附录中的实验结果可以进一步证实**低频扰动的有效性不是因为对扰动搜索空间的限制，而是因为低频分量本身**。

## 观察和分析

1. DCT_Low 在对抗训练模型上可以更快地生成有效扰动，但是在未经对抗训练的原始模型上不行。

   图2(a)和2(b)展示了白盒攻击对抗训练模型和原始模型上的ASR。

   对于对抗训练模型，可以看出在无目标攻击场景下迭代次数为1时以及有目标攻击场景下迭代次数为10时，DCT_Low 都提升了ASR。只有在无目标攻击场景下迭代次数为10时，ASR没提升，但性能仍然超过了其他频率分量并且与原本的MIM性能差距并不大。

   对于原始模型，虽然DCT_Low仍然比其他频率分量表现得更好，但是却比原始的MIM方法表现糟糕。对比(a)(b)二图，可以清楚地看出DCT_low在两种模型上的ASR性能是相似的，这里的区别主要是在于MIM方法在原始模型上表现效果更好。这说明**低频分量优先对于攻击有一定防御措施的模型是有用的**。

2. DCT_Low 绕过了添加了预处理的对抗训练模型。在灰盒攻击案例中，对抗样本是通过对抗训练模型生成的，而用于攻击的模型是在对抗训练模型加上一层预处理层的模型。图2(c)展示了灰盒攻击的结果。可以看到DCT_Low 在所有情况都大幅超过了MIM方法。

## 总结

本文除了证实低频分量的扰动有效是因为低频分量本身的使用而不是搜索空间减少之外，还阐述了其他现象。

**低频扰动不能提升对原始模型（未采取任何加固措施）的攻击（无论是黑盒还是白盒）性能。**本文的实验结果说明最新的针对ImageNet的防御基于不完善的对抗训练，只是明显地减少了低频子空间外的脆弱程度，但是没用针对低频子空间防御。因此低频扰动对经过对抗训练加固的模型攻击比原始模型更有效。对于未加固的原始模型，限制扰动在维度减少了的子空间是无益的，因为原始模型在低频子空间外同样具有脆弱性。

因此，探究观察到的脆弱性是因为低频子空间固有的难以变得鲁棒的特质还是单纯因为对抗训练过程很少从低频区域采样是一个有趣的方向，值得进一步探索。

**低频扰动是易感知的。**下图展示了低频扰动分量在$l_{\infty}$范数$\epsilon=32$下生成的对抗样本。可以看到，在低频分量尺寸小于128时，人类可以明显看出扰动的存在（易感知）。因为，作者希望在设计扰动时，能够不仅考虑频率空间还要考虑总体上的感知先验。

![image-20201212111956557](https://i.loli.net/2020/12/12/THBQdWMzmwAelfb.png)

## 参考文献

[1] Dong, Yinpeng, et al. "Boosting adversarial attacks with momentum." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2018.





